
형태소 분석기를 이용한 비슷한 유형 검색가능





\$\{([^}]+)\}



-- 테이블 구조 복사
--create table s3file_20231125 (like s3file including all);
-- 추가로 데이터도 넣어주기
--insert into s3file_20231125 (select * from s3file);




pgloader를 이용한 로컬 db 마이그레이션
docker run --rm -it --network="host" ffflorian/pgloader pgloader --debug --with "prefetch rows = 500" pgsql://anypoint:'*emflaj*'@prod-reds.cluster-cbth1bnhfbdg.ap-northeast-2.rds.amazonaws.com:5432/flowerdb pgsql://anypoint:'*emflaj*'@dev-ff-pg.cluster-cbth1bnhfbdg.ap-northeast-2.rds.amazonaws.com:5432/redsdb_20240425

docker run --rm -it --network="host" ffflorian/pgloader pgloader --debug --with "prefetch rows = 500" pgsql://anypoint:'*emflaj*'@dev-ff-pg.cluster-cbth1bnhfbdg.ap-northeast-2.rds.amazonaws.com:5432/dev pgsql://flower:ffdb@localhost:15432/flowerdb

docker run --rm -it --network="host" ffflorian/pgloader pgloader --debug --with "prefetch rows = 500" pgsql://flower_glue:I9jK1lM3nO5@prod-flower-fragrance.cluster-c0hrasxydgoa.ap-northeast-2.rds.amazonaws.com:5432/flowerdb pgsql://anypoint:'*emflaj*'@dev-ff-pg.cluster-cbth1bnhfbdg.ap-northeast-2.rds.amazonaws.com:5432/uplus_test6

docker run --rm -it --network="host" ffflorian/pgloader pgloader --debug --with "prefetch rows = 500" pgsql://anypoint:'*emflaj*'@dev-ff-pg.cluster-cbth1bnhfbdg.ap-northeast-2.rds.amazonaws.com:5432/base_dev pgsql://flower:'ffdb'@localhost:5432/flowerdb


db내용 복사
create database flowerdb_ori with template flowerdb owner flower

해당 db와 연결된 세션 끊기
SELECT pg_terminate_backend(pg_stat_activity.pid)
FROM pg_stat_activity
WHERE pg_stat_activity.datname = 'flowerdb'
 AND pid <> pg_backend_pid();



 docker run --rm -it --network="host" ffflorian/pgloader pgloader --debug  --with "prefetch rows = 500"  pgsql://flower_glue:I9jK1lM3nO5@prod-flower-fragrance.cluster-c0hrasxydgoa.ap-northeast-2.rds.amazonaws.com:5432/flowerdb pgsql://anypoint:'*emflaj*'@dev-ff-pg.cluster-cbth1bnhfbdg.ap-northeast-2.rds.amazonaws.com:5432/uplus_test5



* https://mikefarah.gitbook.io/yq/usage/convert
https://github.com/nvbn/thefuck
* https://stedolan.github.io/jq/


마지막 db에 적용하는 부분에는 특수 동작이 있으면 않됨 < 싹다 서비스 레이어로 올려서 해야함 > 간단crud 쿼리가 있다면 해당 쿼리 또는 jpa에는 특수값이 없어야 한다.
ex: insert id: 1

mq정리
네, 맞습니다. RabbitMQ와 Apache Kafka는 메시징 시스템으로서 각각의 설계 철학과 데이터 처리 방식이 다릅니다. 이로 인해 메시지의 전송 및 소비 방식에 차이가 있습니다. 아래에 두 시스템의 주요 차이점을 설명하겠습니다.

### RabbitMQ

#### 큐 기반 메시징

- **메시지 전송 및 소비:** RabbitMQ는 큐 기반의 메시징 시스템입니다. 메시지는 생산자(Producer)가 큐에 전송하고, 소비자(Consumer)는 큐에서 메시지를 읽어옵니다. 큐는 메시지를 저장하고, 소비자가 큐에서 메시지를 소비할 때까지 유지됩니다.

- **컨슈머의 큐 관찰:** 컨슈머는 특정 큐를 모니터링하고, 큐에 새로운 메시지가 들어오면 이를 소비합니다. 큐는 FIFO(First In, First Out) 방식으로 메시지를 처리합니다(기본적으로).

- **예시:**
  ```php
  // 큐에 메시지 전송
  $channel->basic_publish($msg, '', 'my_queue');

  // 큐에서 메시지 소비
  $channel->basic_consume('my_queue', '', false, true, false, false, function($msg) {
      echo 'Received: ', $msg->body, "\n";
  });
  ```

#### 특징

- **메시지 라우팅:** RabbitMQ는 교환기(Exchange)와 라우팅 키를 사용하여 메시지를 다양한 큐로 라우팅할 수 있습니다. 복잡한 라우팅 로직을 구현할 수 있습니다.

- **메시지 보존:** 큐에 저장된 메시지는 소비자에게 전달될 때까지 큐에 보존됩니다.

- **다양한 패턴 지원:** RPC(원격 프로시저 호출), pub/sub(발행/구독), 라우팅 등 다양한 메시징 패턴을 지원합니다.

### Apache Kafka

#### 토픽 기반 메시징

- **메시지 전송 및 소비:** Kafka는 토픽 기반의 스트리밍 플랫폼입니다. 생산자는 토픽에 메시지를 전송하고, 소비자는 토픽을 구독(subscribe)하여 메시지를 읽어옵니다. 토픽은 데이터 스트림의 카테고리 역할을 합니다.

- **컨슈머의 토픽 구독:** 컨슈머는 특정 토픽을 구독하고, 토픽에 기록된 메시지를 읽습니다. Kafka에서는 메시지가 토픽에 순서대로 저장되며, 각 파티션(partition) 내에서 오프셋(offset)을 기반으로 메시지를 읽습니다.

- **예시:**
  ```php
  // 메시지 전송
  $producer->produce('my_topic', RD_KAFKA_PARTITION_UA, 'message body');

  // 메시지 소비
  $consumer->subscribe(['my_topic']);
  while (true) {
      $message = $consumer->consume(0, 1000);
      echo 'Received: ', $message->payload, "\n";
  }
  ```

#### 특징

- **데이터 스트림:** Kafka는 메시지를 연속적으로 기록하고, 메시지는 토픽의 파티션에 오프셋을 기준으로 저장됩니다. 데이터는 지정된 보존 기간 동안 저장되며, 소비자는 오프셋을 기반으로 메시지를 읽습니다.

- **파티션 및 오프셋:** Kafka는 데이터를 여러 파티션에 분산 저장하며, 각 파티션은 독립적으로 데이터를 읽고 쓸 수 있습니다. 소비자는 오프셋을 기반으로 메시지를 처리하며, 메시지의 위치를 추적합니다.

- **고가용성 및 확장성:** Kafka는 분산 시스템으로 설계되어 있어 높은 확장성과 고가용성을 제공합니다. 데이터는 여러 브로커에 복제되어 저장됩니다.

### 요약

- **RabbitMQ:** 큐를 기반으로 하며, 컨슈머는 특정 큐를 모니터링하여 메시지를 소비합니다. 메시지 라우팅과 다양한 메시징 패턴을 지원합니다.

- **Kafka:** 토픽을 기반으로 하며, 컨슈머는 특정 토픽을 구독하여 메시지를 읽습니다. 데이터는 파티션에 오프셋을 기준으로 저장되고, 스트리밍 데이터 처리에 적합합니다.

이러한 차이점은 시스템의 설계와 요구 사항에 따라 적절한 메시징 시스템을 선택하는 데 중요한 요소입니다. RabbitMQ는 큐와 교환기를 통한 복잡한 메시징 패턴을 지원하며, Kafka는 대량의 데이터를 스트리밍하고 저장하는 데 적합합니다.
